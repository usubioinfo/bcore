{% set faqRnaSeq = [
  {
	question: "How much sequencing depth (number of reads) needed for a Differential Gene Expression (DEG) analysis?",
	content: "<ol> <li>a.The amount of sequencing needed for a given sample is determined by the goals of the experiment and the nature of the RNA sample.</li>
<li>b.Experiments whose purpose is to evaluate the similarity between the transcriptional profiles of two polyA+ samples may require only modest depths of sequencing (e.g. 30M pair-end reads of length > 30NT, of which 20-25M are 3 mappable to the genome or known transcriptome.</li>
<li>c.Experiments whose purpose is the discovery of novel transcribed elements and strong quantification of known transcript isoforms requires more extensive sequencing. The ability to detect reliably low copy number transcripts / isoforms depends upon the depth of sequencing and on a sufficiently complex library.</li>
<li>d.For experiments from a typical mammalian tissue or in which sensitivity of detection is important, a minimum depth of 100-200 M 2 x 76 bp or longer reads is currently recommended.</li>
<li>e.Specialized studies in which the prevalence of different RNAs has been intentionally altered (e.g. “normalizing” using DSN) as part of sample preparation need more than the read amounts (>30M paired-end reads) used for simple comparison. Reasons for this include: (1) overamplification of inserts as a result of an additional round of PCR after DSN, and (2) much more broad coverage given the nature of A(-) and low abundance transcripts.</li></ol>"
  },
  {
    question: "Paired-end or Single-end reads? ",
    content: "<ol> <li>a.Single-end is fine for simple RNA-Seq analysis.</li>
<li>b.Paired-end would be required if we are looking for novel transcripts. Paired-end RNA sequencing (RNA-Seq) enables discovery applications such as detecting gene fusions in cancer and characterizing novel splice isoforms. For paired-end RNA-Seq, use the TruSeq RNA Library Prep Kits with an alternate fragmentation method, followed by standard Illumina paired-end cluster generation and sequencing.</li></ol>"
  },
  {
    question: "In  terms  of  coverage  /  amount  of  data  generated,  how  does  one  lane  of  NextSeq  compare  with one lane of HiSeq?",
    content: "The HiSeq maximum yield is about 200 mil reads. Roughly, one could figure 160 to 180 mil reads to be a safe count. This is enough for a 4 to 6 plex samples at 30M reads per RNA sample. The NextSeq has a max of about 400M reads. Figure  360M to  be safe. This is enough for a  10  to  12 plex at 30M reads per  RNA  sample.  Yes,  the  NextSeq  do  twice  the  plex  level  as  the  HiSeq.  Plus  it  does  a  75bp  read  as opposed to a 50bp read. So it is cheaper per base."
  },
  {
    question: "Length of reads?",
    content: "50bp is sufficient for simple RNA-Seq analysis"
  },
  {
    question: "How many biological replicates are needed?",
    content: "At least 3 (more if you can afford)"
  },
  {
    question: "Do we need to include spike-in controls for RNA-seq normalization?",
    content: 'There is no standard whether to use spike-in control or not, I guess it varies case to case. During sequencing there are so many unknown factors one can’t control, so including a spike-in would be better as this would allow to evaluate performance of library preparation and sequencing, and thus less unbiased call for differential gene expression in later stages. However, there have been studies that says the spike-in controlled data may be very biased to various degree unless the experiments are designed in a careful way to preserve and capture true biological variations represented in your sample. As the spike-in datasets represent only technical replicates with minimal variation, this could be complemented with more practical comparisons in real datasets with true biological replicates. For example, this study (<a href="http://europepmc.org/articles/pmc4404308">http://europepmc.org/articles/pmc4404308</a>) reports that spike-ins are not reliable enough to be used in standard global-scaling or regression-based normalization procedures. One of the advantages of using spike controls for normalization is the possibility of relaxing the common assumption that majority of the genes are not DE between the conditions under study. So if you want to use the spike-ins for normalization, two conditions must be satisfied: (i) spike-in read counts are not affected by the biological factors of interest,  and (ii) the unwanted variation should affect the spike-in and gene read counts similarly.<br><br>
One should not confuse with the definition of spike-ins, the one between PhiX (used for quality-control during sequencing) and the spike-ins for normalization purposes. To some extent, both are useful for quality control and for library-size normalization. There is an External RNA Control Consortium (ERCC) that had developed a set of 92 synthetic spike-in standards that are commercially available and relatively easy to add to a typical library preparation. So you can select various formulation mixes of controls from these kits (or could be custom made) and use in your experiments. Ambion (Life Technologies) is the only company that manufactures such spike-in controls for normalization purpose. You can find step-by-step details here on how and when to use Spike-ins <a href="https://tools.thermofisher.com/content/sfs/manuals/cms_086340.pdf">https://tools.thermofisher.com/content/sfs/manuals/cms_086340.pdf</a>. The main idea here is to achieve a standard measure for data comparison across gene expression experiments, measure sensitivity (lower the limit of detection) and dynamic range of an experiment, and quantitate differential gene expression.'
  },
  {
    question: "How important is the use of Spike-ins?",
    content: 'In  the  view  of  DE  analysis,  all  the  normalization  methods  what  we  employ  during  the bioinformatics analysis downstream for between-sample normalizations thus far work properly, because we assume that majority of the genes are NOT differentially expressed between conditions under study, a  reasonable  assumption  in  most  applications.  Note  that  in  practice,  most  of  the  normalization procedures (bioinfo based, not spike-in based) work well even when a high proportion of genes are DE, provided that they are roughly equally distributed between up-and down-regulation. However, in cases where  there  is  a  major  global  shift  in  expression,  the  usual  between-sample  normalization  procedures will  fail.  In  this  case,  normalization  based  on  control  sequences  (spike-ins)  may  be  the  only  option. There  is  a  very  nice  book  chapter  here  (<a href="http://link.springer.com/chapter/10.1007%2F978-3-319-07212-8_9#page-1">http://link.springer.com/chapter/10.1007%2F978-3-319-07212-8_9#page-1</a>) where it explains in detail about the role of spike-ins for normalization of RNA-seq.'
  },
  {
    question: "Is it standard to use spike-ins in every RNA-seq experiment?",
    content: 'It  depends  on  a  case  to  case  basis.  Although  there  are  very  few  reports  in  literature  where people have actually used spike-ins in real experiments. This is surprising. Maybe because of time and money, this is not always possible. Because most of the major RNA-seq guidelines and forums strongly recommend using spike-ins during the experiment designing and sequencing. The approach is strongly recommended by the ENCODE consortium (<a href="http://genome.ucsc.edu/ENCODE/protocols/dataStandards/ENCODE_RNAseq_Standards_V1.0.pdf">http://genome.ucsc.edu/ENCODE/protocols/dataStandards/ENCODE_RNAseq_Standards_V1.0.pdf</a>). Then  there  is  one  recent  paper  just  published  in  2016  (A  survey  of  best  practices  for  RNA-seq)(<a href="https://genomebiology.biomedcentral.com/articles/10.1186/s13059-016-0881-8">https://genomebiology.biomedcentral.com/articles/10.1186/s13059-016-0881-8</a>) which also recommends including the spike-ins for both the quality control as well as for library-size normalization. Another good read is (Synthetic spike-in standards for RNA-seq experiments) (<a href="http://www.ncbi.nlm.nih.gov/pubmed/21816910">http://www.ncbi.nlm.nih.gov/pubmed/21816910</a>),   and   Revisiting   global   gene   expression   analysis (<a href="http://www.sciencedirect.com/science/article/pii/S0092867412012263">http://www.sciencedirect.com/science/article/pii/S0092867412012263</a>).<br><br>
                    In any case, it is essential to ensure that spike-in standards behave as expected and to develop a set of controls that are stable enough across the replicate libraries and robust to both the differences in library composition as well as library preparation methods.'
  },
  {
    question: "How do we check the quality and trim/filter low quality reads?",
    content: "One can run FastQC and FASTX tool kit"
  },
  {
    question: "Reference genome or Transcriptome?",
    content: "<ol> <li>a.Depends on the purpose of the experiment</li>
<li>b.Build a reference transcriptome if not available (Trinity, Trans-ABySS, Velvet / Oases)</li>
<li>c.What if I don’t have a good reference genome?<br>
To determine whether the reference genome is well annotated or not; one approach could be, for example, take a random sample of raw reads (100 or so) from both the first and second strand of your paired-end data and BLAST them. If the genome assembly is poor, you would see that one pair of the read map to a different scaffold of the other read. Usually in the paired-end RNA-seq data, the reads must be less than 1000 bases apart on the same chromosome, or much closer. If this technique does not work, then you have to do de novo assembly of your reads and then align your reads against this transcriptome. I think you can combine both approaches. It is common to perform de novo assembly when reference genome is not available or is poorly annotated. Basically you are assembling your reads into longer contigs and then to treat those contigs as the expressed transcriptome to which the raw reads are mapped back again for quantification. There are several tools available for this.</li></ol>"
  },
  {
    question: "What alignment program one can use to map the reads to a reference genome?",
    content: "TopHat, Bowtie2, BWA"
  },
  {
    question: "Unique or multiple mapping?",
    content: "<ol><li>a.Unique</li>
<li>b.A good mapping % is between 70 to 90%</li></ol>"
  },
  {
    question: "How to get read counts?",
    content: "HTSeq with using the option ‘union’"
  },
  {
    question: "What statistical methods one can use for DEG analysis?",
    content: ""
  },
  {
    question: "Why do we use more than one method?",
    content: "All  the  DEG  analysis  tools  are  developed  based  on  different  normalization  methods  and assumptions. There is no single tool that can be declared better over other."
  },
  {
    question: "How to select genes?",
    content: "FDR (1% to 5%), Fold Change (FC), Pathway"
  },
  {
    question: "What is RPKM and how itis calculated?",
    content: "C = Number of reads mapped to a gene<br>
                    N = Total mapped reads in the experiment<br>
                    L = exon length in base-pairs for a gene<br>
                    Equation = RPKM = (10^9 * C)/(N * L)"
  },
  {
    question: "What is the difference between RPKM and FPKM?",
    content: "FPKM=RPKM if we have single-end reads<br>
                    FPKM  is  very  similar  to  RPKM.  RPKM  was  made  for  single-end  RNA-seq,  where  every  read corresponded to a single fragment that was sequenced. FPKM was made for paired-end RNA-seq. With paired-end RNA-seq, two reads can correspond to a single fragment, or, if one read in the pair did not map, one read can correspond to a single fragment. The only difference between RPKM and FPKM is that  FPKM  takes  into  account  that  two  reads  can  map  to  one  fragment  (and  soit doesn’t count this fragment twice)."
  },
  {
    question: "In the  output file, what the  five  different  columns  represent  / means  in a  usual edgeR  pair-wise DEG analysis?",
    content: '<ol> <li>a. Column-1  (logFC): For  a  particular  gene,  a  log2  fold  change  of  −1  for  condition  treated  vs untreated  means that the treatment induces a change in observed expression level of 2^−1 = 0.5 compared to the untreated condition.<br>
                      logFC -Fold change, generally refers to the ratio of average expression between two groups. edgeR uses exactTest() performs pair-wise tests for differential expression between two groups.<br> log2FC=Log2(B)-Log2(A)<br>
                      When you\'re comparing two things: A and B, the fold change is A/B. A and B could be data sets reflecting gene expression measured under different conditions. If gene1 is 2-fold higher in A, the A/B ratio for gene1 is 2. If gene2 is 2-fold higher in B than A, the gene2 ratio is 0.5. However, edgeR displays the log2 of the ratio. Therefore genes up or down by a given amount (i.e. two-fold) have the same distance from equality, but the sign (+/-) changes. Thus gene1 would have logFC: 1, and gene2 would have logFC: -1, reflecting 2-fold up or down respectively. In log2 space the numbers are close enough. For instance: -2 is 4-fold down, -1 is 2-fold down, 0 is equal in A and B (a ratio of 1), 1 is 2-fold up, 2 is 4-fold up, etc. To convert the logFC value from edgeR (which are essentially ratios of the normalized count values per gene) into an up or down ratio, you simply take 2 to the power of the logFC number. e.g. for a gene with logFC of 0.5 or -0.5: the ratio is 2^0.5 = 1.4, or 2^-0.5 = 0.7, respectively.<br>
                      Let\'s say there are 50 read counts in control and 100 read counts in treatment for gene A. This means  gene A is  expressing twice in treatment as compared to control (100 divided by 50 =2) or  fold  change  is  2.  This  works  well  for  over  expressed  genes  as  the  number  directly corresponds  to  how  many  times  a  gene  is  overexpressed. But when  it  is  other  way  round  (i.e, treatment  50,  control  100),  the  value  of  fold  change  will  be  0.5  (all  underexpressed  genes  will have values between 0 to 1, while overexpressed genes will have values from 1 to infinity). To make this leveled, we use log2 for expressing the fold change. I.e, log2 of 2 is 1 and log2 of 0.5 is -1.<br>
                      <b>The log Fold change value is calculated by taking the log2 of avg CPM value of mutant vs control. log2(avg.cpm.mut)/(avg.cpm.wt)</b><br>
                      <a href="http://seqanswers.com/forums/showthread.php?t=26610">http://seqanswers.com/forums/showthread.php?t=26610</a></li>
                      <li>Column-2 (logCPM):<br>
                      log CPM refers to log (Counts per million reads).<br> 
                      <b>To calculate CPM manually in R it would be :<br>
                      cpm <-apply(countmatrix,2, function(x) (x/sum(x))*1000000)<br> 
                      # the 1 added to log function is to avoid log 0 values<br>
                      log.cpm <-log(cpm + 1)<br></b>
                      </li><li> c. Column-3 (LR): Log Ratio / Likelihood Ratio: log2(X1 RPKM/ X2 RPKM).<br>
                      But, edgeR does not use RPKM, instead it calculates CPM (Counts per million). edgeR does not consider the  length  of  the  gene  for  normalization.  Read  counts  can  generally  be  expected  to  be  proportional  to length  as  well  as  to  expression  for  any  transcript,  but  edgeR  does  not  generally  need  to  adjust  for  gene length because gene length has the same relative influence on the read counts for each RNA sample. For this  reason,  normalization  issues  arise  only  to  the  extent  that  technical  factors  have  sample-specific effects.
                      </li><li> d. Column-4 (PValue): 
                      </li><li> e. Column-5  (FDR): FDR  values  were  calculated  using  the  method  of  Benjamini  and  Hochberg  from  the distribution  of  2-way  ANOVA  p-values,  and  fold-change  values  were  calculated  on  a  linear  scale  using least squares mean.</li></ol>'
  },
  {
    question: "In a DEG analysis using edgeR, I noticed that few genes show \'NA\'' in the output file. What does this represent, and how it is calculated within edgeR?",
    content: 'edgeR  uses  a  filtering  criteriato  remove  the  genes  with  low  filter  counts. Please  refer  to  page 11 of the edgeR user guide.<br>
                    <a href="https://www.bioconductor.org/packages/3.3/bioc/vignettes/edgeR/inst/doc/edgeRUsersGuide.pdf">https://www.bioconductor.org/packages/3.3/bioc/vignettes/edgeR/inst/doc/edgeRUsersGuide.pdf</a><br>
                    “A requirement for expression in two or more libraries is used as the minimum number of samples in each  group  is  two”. This ensures that a gene will be retained if it is only expressed in at least two groups.  Internally,  edgeR  is  using  the  following  code  to  filter  out  the  genes  based  on  the  CPM (Counts per million) values.<br>
                    > keep <-rowSums(cpm(y)>1) >= 2<br>
                    > y <-y[keep, , keep.lib.sizes=FALSE]<br>
                    So by default, the cases that do not contain CPM of 1 or greater for at least 2 replicates, will be filtered out and thus gives \'NA\' in the results file. Generally, it is preferred to use 3 replicates for RNA-Seq analysis, so a threshold of 2 works fine. In any case, if one would like to use a threshold of 1, the code could be modified.'
  },
  {
    question: "How much total RNA is required for RNA-Seq projects?",
    content: "The following specifications apply to total RNA samples:
                    
                      <ul><li>Total amount: ≥ 5 μg</li>
                      <li>Concentration: ≥ 80 ng/μl</li>
                      <li>OD260/280 Range: 1.8-2.2</li>
                      <li>Re-suspended in nuclease-free water</li></ul>"
  },
  {
    question: "Resources for RNA-Seq analysis:",
    content: '<ul><li>SEQanswers (<a href="http://seqanswers.com/">http://seqanswers.com/</a>)</li>
                      <li>BioStars (<a href="https://www.biostars.org/">https://www.biostars.org/</a>)</li>
                      <li>Bioinformatics, Oxford Journals (<a href="http://www.oxfordjournals.org/our_journals/bioinformatics/nextgenerationsequencing.html">http://www.oxfordjournals.org/our_journals/bioinformatics/nextgenerationsequencing.html</a>)</li>
                      <li>RNA-Seq Blog (<a href="http://www.rna-seqblog.com/">http://www.rna-seqblog.com/</a>)</li></ul>'
  }

] %}